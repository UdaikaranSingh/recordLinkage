{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim.models\n",
    "from gensim import utils\n",
    "from graph import *\n",
    "import networkx as nx\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    \n",
    "    def __init__(self, pt, groundTruth, testProp, p, q):\n",
    "        self.path = pt\n",
    "        print('building train/test sets')\n",
    "        self.build(pt, testProp,groundTruth)\n",
    "        self.p = p\n",
    "        self.q = q\n",
    "        print('building graph')\n",
    "        self.generateCorpus()\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    def build(self, pt, testProp, groundTruth):\n",
    "        #note: temp1 is the training/test set; temp2 is the graph\n",
    "        df = pd.read_csv(pt).astype(str) \n",
    "        temp1 = pd.read_csv(groundTruth)\n",
    "        print(list(temp1.columns))\n",
    "        temp1 = self.generateNegativeSamples(temp1)\n",
    "        self.trainTestSplit(temp1, testProp)\n",
    "        self.buildGraph(df)\n",
    "    \n",
    "    def generateNegativeSamples(self,df):\n",
    "        df['label'] = 1\n",
    "        col1 = df.columns[0]\n",
    "        col2 = df.columns[1]\n",
    "        allItems = set(df[col1])\n",
    "        negSamples = []\n",
    "        for i, row in df.iterrows():\n",
    "            source = row[col1]\n",
    "            target = row[col2]\n",
    "            negSamples.append((source, random.sample(allItems.difference(set([target])), 1)[0]))\n",
    "        t = pd.DataFrame(negSamples, columns = [col1,col2])\n",
    "        t['label'] = 0\n",
    "        return pd.concat([t, df])\n",
    "    \n",
    "    \n",
    "    def trainTestSplit(self, df, testProp):\n",
    "        df = df.sample(len(df))\n",
    "        nodes = set(df[df.columns[1]].values)\n",
    "        nodes.update(set(df[df.columns[0]].values))\n",
    "        self.nodes = [str(x) for x in list(nodes)]\n",
    "        cutoff = int(len(df) * testProp)\n",
    "        test = df.iloc[0:643]\n",
    "        train = df.iloc[643:]\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "    \n",
    "    def buildGraph(self, df):\n",
    "        G=nx.Graph()\n",
    "        \n",
    "        temp = set([str(x) for x in df['source']])\n",
    "        temp.update(set([str(x) for x in df['target']]))\n",
    "        edges = tuple(zip([str(x) for x in list(df['source'])], [str(x) for x in list(df['target'])]))\n",
    "        G.add_nodes_from(temp)\n",
    "        G.add_edges_from(edges, weight = 1)\n",
    "        self.G = G\n",
    "    \n",
    "    def generateCorpus(self):\n",
    "        self.corpus = Graph(self.G, self.nodes, is_directed= False, p = self.p, q = self.q)\n",
    "        self.corpus.preprocess_transition_probs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \n",
    "    def __init__(self, corpus, embedder = None, model = None):\n",
    "        self.corpus = corpus\n",
    "        self.embedder = embedder\n",
    "        self.model = model\n",
    "    \n",
    "    def trainW2V(self, numWalks, walkLength, embedLength):\n",
    "        sentences = test.corpus.simulate_walks(numWalks,walkLength)\n",
    "        if (self.embedder == None):\n",
    "            self.embedder = Word2Vec(sentences, size=embedLength, workers=4)\n",
    "        else:\n",
    "            self.embedder.build_vocab(more_sentences, update=True)\n",
    "            self.embedder.train(sentences, total_examples=self.embedder.corpus_count, epochs=self.embedder.iter)\n",
    "    \n",
    "    def saveW2V(self, fname):\n",
    "        self.embedder.save(fname)\n",
    "    \n",
    "    def loadW2V(self, fname):\n",
    "        self.embedder = gensim.models.Word2Vec.load(fname)\n",
    "    \n",
    "    def trainModel(self):\n",
    "        trainData = corpus.train\n",
    "        pass\n",
    "    \n",
    "    def saveModel(self, fname):\n",
    "        pass\n",
    "    \n",
    "    def loadModel(self, fname):\n",
    "        pass\n",
    "    \n",
    "    def evaluate(self, setType = 'train'):\n",
    "        pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note: place model into a seperate class with calls on Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>38477</td>\n",
       "      <td>10011646</td>\n",
       "      <td>ground_truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>38475</td>\n",
       "      <td>10140760</td>\n",
       "      <td>ground_truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>33053</td>\n",
       "      <td>10221960</td>\n",
       "      <td>ground_truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>27248</td>\n",
       "      <td>10246269</td>\n",
       "      <td>ground_truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>25262</td>\n",
       "      <td>10315184</td>\n",
       "      <td>ground_truth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62761</td>\n",
       "      <td>31992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62762</td>\n",
       "      <td>34697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62763</td>\n",
       "      <td>210252385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62764</td>\n",
       "      <td>38346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62765</td>\n",
       "      <td>90105458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62766 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          source    target          type\n",
       "0          38477  10011646  ground_truth\n",
       "1          38475  10140760  ground_truth\n",
       "2          33053  10221960  ground_truth\n",
       "3          27248  10246269  ground_truth\n",
       "4          25262  10315184  ground_truth\n",
       "...          ...       ...           ...\n",
       "62761      31992       NaN           NaN\n",
       "62762      34697       NaN           NaN\n",
       "62763  210252385       NaN           NaN\n",
       "62764      38346       NaN           NaN\n",
       "62765   90105458       NaN           NaN\n",
       "\n",
       "[62766 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../data/gen/abt_buy_graph.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.models.doc2vec.FAST_VERSION > -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building train/test sets\n",
      "['idAbt', 'idBuy']\n",
      "building graph\n"
     ]
    }
   ],
   "source": [
    "test = Corpus(\"../data/gen/abt_buy_graph.csv\", '../data/Abt-Buy/abt_buy_perfectMapping.csv', 0.3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk iteration:\n",
      "1 / 1000\n",
      "2 / 1000\n",
      "3 / 1000\n",
      "4 / 1000\n",
      "5 / 1000\n",
      "6 / 1000\n",
      "7 / 1000\n",
      "8 / 1000\n",
      "9 / 1000\n",
      "10 / 1000\n",
      "11 / 1000\n",
      "12 / 1000\n",
      "13 / 1000\n",
      "14 / 1000\n",
      "15 / 1000\n",
      "16 / 1000\n",
      "17 / 1000\n",
      "18 / 1000\n",
      "19 / 1000\n",
      "20 / 1000\n",
      "21 / 1000\n",
      "22 / 1000\n",
      "23 / 1000\n",
      "24 / 1000\n",
      "25 / 1000\n",
      "26 / 1000\n",
      "27 / 1000\n",
      "28 / 1000\n",
      "29 / 1000\n",
      "30 / 1000\n",
      "31 / 1000\n",
      "32 / 1000\n",
      "33 / 1000\n",
      "34 / 1000\n",
      "35 / 1000\n",
      "36 / 1000\n",
      "37 / 1000\n",
      "38 / 1000\n",
      "39 / 1000\n",
      "40 / 1000\n",
      "41 / 1000\n",
      "42 / 1000\n",
      "43 / 1000\n",
      "44 / 1000\n",
      "45 / 1000\n",
      "46 / 1000\n",
      "47 / 1000\n",
      "48 / 1000\n",
      "49 / 1000\n",
      "50 / 1000\n",
      "51 / 1000\n",
      "52 / 1000\n",
      "53 / 1000\n",
      "54 / 1000\n",
      "55 / 1000\n",
      "56 / 1000\n",
      "57 / 1000\n",
      "58 / 1000\n",
      "59 / 1000\n",
      "60 / 1000\n",
      "61 / 1000\n",
      "62 / 1000\n",
      "63 / 1000\n",
      "64 / 1000\n",
      "65 / 1000\n",
      "66 / 1000\n",
      "67 / 1000\n",
      "68 / 1000\n",
      "69 / 1000\n",
      "70 / 1000\n",
      "71 / 1000\n",
      "72 / 1000\n",
      "73 / 1000\n",
      "74 / 1000\n",
      "75 / 1000\n",
      "76 / 1000\n",
      "77 / 1000\n",
      "78 / 1000\n",
      "79 / 1000\n",
      "80 / 1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-3e3acc5da8c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulate_walks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/recordLinkage/notebooks/graph.py\u001b[0m in \u001b[0;36msimulate_walks\u001b[0;34m(self, num_walks, walk_length)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mwalks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode2vec_walk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalk_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwalk_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwalks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/recordLinkage/notebooks/graph.py\u001b[0m in \u001b[0;36mnode2vec_walk\u001b[0;34m(self, walk_length, start_node)\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     next = cur_nbrs[alias_draw(alias_edges[(prev, cur)][0], \n\u001b[0;32m---> 33\u001b[0;31m                         alias_edges[(prev, cur)][1])]\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0mwalk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/recordLinkage/notebooks/graph.py\u001b[0m in \u001b[0;36malias_draw\u001b[0;34m(J, q)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mkk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t = test.corpus.simulate_walks(1000,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = gensim.models.Word2Vec(sentences = t, workers=-1, size=100, sg = 1, hs = 0, negative = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test.train\n",
    "embedding1 = mdl[[str(x) for x in df.idAbt.values]]\n",
    "embedding2 = mdl[[str(x) for x in df.idBuy.values]]\n",
    "data = np.concatenate([embedding1,embedding2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df2 = test.test\n",
    "embedding1 = mdl[[str(x) for x in df2.idAbt.values]]\n",
    "embedding2 = mdl[[str(x) for x in df2.idBuy.values]]\n",
    "data2 = np.concatenate([embedding1,embedding2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data.reshape(-1, 1), df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.533204384268214"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(data.reshape(-1, 1), df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48522550544323484"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(data2.reshape(-1, 1), df2.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "204238996 in pd.read_csv('../data/Abt-Buy/abt_buy_perfectMapping.csv').idBuy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('../data/Abt-Buy/abt_buy_perfectMapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.corpus.simulate_walks(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.test.label.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.train.label.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/gen/abt_buy_graph.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = df[df['type'] == 'ground_truth']\n",
    "temp2 = df[df['type'] != 'ground_truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = temp1.drop(columns = 'type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.fast_gnp_random_graph(n=100, p=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph[0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allItems = set(temp2.source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = set(df.source)\n",
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.update(set(df.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [str(x) for x in list(temp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = tuple(zip([str(x) for x in list(df['source'])], [str(x) for x in list(df['target'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(G.neighbors('nan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/gen/abt_buy_graph.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['target','type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.simple_preprocess('cat dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences = ['dog, cat']\n",
    "model = gensim.models.Word2Vec(sentences=utils.simple_preprocess('cat dog'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
